{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 数据操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.1 创建`Tensor`\n",
    "\n",
    "创建一个5x3的未初始化的`Tensor`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.6675e+21, 4.5730e-41, 1.6105e-38],\n",
      "        [3.0858e-41, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.4013e-45, 0.0000e+00, 0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建一个5x3的随机初始化的`Tensor`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4963, 0.7682, 0.0885],\n",
      "        [0.1320, 0.3074, 0.6341],\n",
      "        [0.4901, 0.8964, 0.4556],\n",
      "        [0.6323, 0.3489, 0.4017],\n",
      "        [0.0223, 0.1689, 0.2939]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "创建一个5x3的long型全0的`Tensor`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "创建一个5x3的long型全1的`Tensor`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建一个单位矩阵：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 0, 0],\n",
      "        [0, 1, 0, 0],\n",
      "        [0, 0, 1, 0],\n",
      "        [0, 0, 0, 1]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "x = torch.eye(4, 4, dtype=torch.int)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  3,  5,  7,  9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35,\n",
      "        37, 39, 41, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61, 63, 65, 67, 69, 71,\n",
      "        73, 75, 77, 79, 81, 83, 85, 87, 89, 91, 93, 95, 97, 99])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([1.0000, 1.4444, 1.8889, 2.3333, 2.7778, 3.2222, 3.6667, 4.1111, 4.5556,\n",
      "        5.0000])\n"
     ]
    }
   ],
   "source": [
    "# 从s到e，步长为step\n",
    "x = torch.arange(1, 100, 2)\n",
    "print(x)\n",
    "\n",
    "x = torch.arange(1, 5)\n",
    "print(x)\n",
    "\n",
    "# 从s到e，均匀切分成steps份\n",
    "x = torch.linspace(1, 5, 10)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "randperm（m）：随机打乱一个数字序列\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 1, 0, 7, 3, 2, 9, 5, 8, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randperm(10)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "直接根据数据创建:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还可以通过现有的`Tensor`来创建，此方法会默认重用输入`Tensor`的一些属性，例如数据类型，除非自定义数据类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[-0.8567,  1.1006, -1.0712],\n",
      "        [ 0.1227, -0.5663,  0.3731],\n",
      "        [-0.8920, -1.5091,  0.3704],\n",
      "        [ 1.4565,  0.9398,  0.7748],\n",
      "        [ 0.1919,  1.2638, -1.2904]])\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(5, 3, dtype=torch.float64)      # 返回的tensor默认具有相同的torch.dtype和torch.device\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x, dtype=torch.float)    # 指定新的数据类型\n",
    "print(x)\n",
    "\n",
    "#below is wrong!\n",
    "#x = torch.randn_like(x, dtype=torch.int)\n",
    "#print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以通过`shape`或者`size()`来获取`Tensor`的形状:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 注意：返回的torch.Size其实就是一个tuple, 支持所有tuple的操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.2 操作\n",
    "### 算术操作\n",
    "* **加法形式一**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1.5932, 1.1123, 1.1535],\n",
      "        [1.2417, 1.7262, 1.7011],\n",
      "        [1.2038, 1.6511, 1.7745],\n",
      "        [1.4369, 1.5191, 1.6159],\n",
      "        [1.8102, 1.9801, 1.1147]])\n",
      "tensor([[10.5932, 10.1123, 10.1535],\n",
      "        [10.2417, 10.7262, 10.7011],\n",
      "        [10.2038, 10.6511, 10.7745],\n",
      "        [10.4369, 10.5191, 10.6159],\n",
      "        [10.8102, 10.9801, 10.1147]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(5, 3)\n",
    "print(x)\n",
    "y = torch.rand(5, 3)\n",
    "print(x + y)\n",
    "\n",
    "y += 10.0\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **加法形式二**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12.5932, 12.1123, 12.1535],\n",
      "        [12.2417, 12.7262, 12.7011],\n",
      "        [12.2038, 12.6511, 12.7745],\n",
      "        [12.4369, 12.5191, 12.6159],\n",
      "        [12.8102, 12.9801, 12.1147]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12.5932, 12.1123, 12.1535],\n",
      "        [12.2417, 12.7262, 12.7011],\n",
      "        [12.2038, 12.6511, 12.7745],\n",
      "        [12.4369, 12.5191, 12.6159],\n",
      "        [12.8102, 12.9801, 12.1147]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(5, 3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **加法形式三、inplace**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[15.5932, 15.1123, 15.1535],\n",
      "        [15.2417, 15.7262, 15.7011],\n",
      "        [15.2038, 15.6511, 15.7745],\n",
      "        [15.4369, 15.5191, 15.6159],\n",
      "        [15.8102, 15.9801, 15.1147]])\n"
     ]
    }
   ],
   "source": [
    "# adds x to y\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **注：PyTorch操作inplace版本都有后缀\"_\", 例如`x.copy_(y), x.t_()`**\n",
    "\n",
    "### 索引\n",
    "我们还可以使用类似NumPy的索引操作来访问`Tensor`的一部分，需要注意的是：**索引出来的结果与原数据共享内存，也即修改一个，另一个会跟着修改。** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3.])\n",
      "tensor([3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "y = x[0, :]\n",
    "y += 1\n",
    "print(y)\n",
    "print(x[0, :]) # 源tensor也被改了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 改变形状\n",
    "用`view()`来改变`Tensor`的形状："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3]) torch.Size([15]) torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "y = x.view(15)\n",
    "z = x.view(-1, 5)  # -1所指的维度可以根据其他维度的值推出来\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**注意`view()`返回的新tensor与源tensor共享内存，也即更改其中的一个，另外一个也会跟着改变。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 4., 4.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]])\n",
      "tensor([4., 4., 4., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.])\n"
     ]
    }
   ],
   "source": [
    "x += 1\n",
    "print(x)\n",
    "print(y) # 也加了1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果不想共享内存，推荐先用`clone`创造一个副本然后再使用`view`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.6035,  1.8110,  0.9549],\n",
      "        [ 0.8797,  1.0482, -0.0445],\n",
      "        [-0.7229,  2.8663, -0.5655],\n",
      "        [ 0.1604, -0.0254,  1.0739],\n",
      "        [ 2.2628, -0.9175, -0.2251]])\n",
      "tensor([2.6035, 2.8110, 1.9549, 1.8797, 2.0482, 0.9555, 0.2771, 3.8663, 0.4345,\n",
      "        1.1604, 0.9746, 2.0739, 3.2628, 0.0825, 0.7749])\n"
     ]
    }
   ],
   "source": [
    "x_cp = x.clone().view(15)\n",
    "x -= 1\n",
    "print(x)\n",
    "print(x_cp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另外一个常用的函数就是`item()`, 它可以将一个标量`Tensor`转换成一个Python number："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3354])\n",
      "-0.33542600274086\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性代数运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = \n",
      "tensor([[ 0.7870,  0.1076, -1.0715, -0.1166, -1.0170],\n",
      "        [-1.4453, -0.8078,  1.1975, -1.3700, -2.7575],\n",
      "        [-0.8324,  0.4900,  0.2908,  0.6442,  3.9300],\n",
      "        [-0.1244,  0.2953,  2.4197,  1.6456, -0.3087],\n",
      "        [-1.5147,  1.9457, -1.2904, -2.3495, -2.0689]])\n",
      "x.trace = \n",
      "tensor(-0.1532)\n",
      "x.diag = \n",
      "tensor([ 0.7870, -0.8078,  0.2908,  1.6456, -2.0689])\n",
      "x.triu = \n",
      "tensor([[ 0.7870,  0.1076, -1.0715, -0.1166, -1.0170],\n",
      "        [ 0.0000, -0.8078,  1.1975, -1.3700, -2.7575],\n",
      "        [ 0.0000,  0.0000,  0.2908,  0.6442,  3.9300],\n",
      "        [ 0.0000,  0.0000,  0.0000,  1.6456, -0.3087],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000, -2.0689]])\n",
      "x.tril = \n",
      "tensor([[ 0.7870,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-1.4453, -0.8078,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.8324,  0.4900,  0.2908,  0.0000,  0.0000],\n",
      "        [-0.1244,  0.2953,  2.4197,  1.6456,  0.0000],\n",
      "        [-1.5147,  1.9457, -1.2904, -2.3495, -2.0689]])\n",
      "x * x = \n",
      "tensor([[ 2.9106e+00, -2.5404e+00,  4.0367e-03,  1.2679e+00, -3.1679e+00],\n",
      "        [ 3.3807e+00, -4.6861e+00,  1.1727e+00,  6.2710e+00,  1.4531e+01],\n",
      "        [-7.6383e+00,  7.4939e+00, -1.9491e+00, -8.5601e+00, -7.6912e+00],\n",
      "        [-2.2760e+00,  8.1907e-01,  5.5709e+00,  4.6020e+00,  8.9523e+00],\n",
      "        [ 4.9605e-01, -7.0861e+00,  5.6225e-01, -2.3258e+00, -3.8905e+00]])\n",
      "x.t = \n",
      "tensor([[ 0.7870, -1.4453, -0.8324, -0.1244, -1.5147],\n",
      "        [ 0.1076, -0.8078,  0.4900,  0.2953,  1.9457],\n",
      "        [-1.0715,  1.1975,  0.2908,  2.4197, -1.2904],\n",
      "        [-0.1166, -1.3700,  0.6442,  1.6456, -2.3495],\n",
      "        [-1.0170, -2.7575,  3.9300, -0.3087, -2.0689]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(5,5)\n",
    "print(\"x = \")\n",
    "print(x)\n",
    "\n",
    "#对角线元素之和(矩阵的迹)\n",
    "print(\"x.trace = \")\n",
    "print(torch.trace(x))\n",
    "\n",
    "#对角线元素\n",
    "print(\"x.diag = \")\n",
    "print(torch.diag(x))\n",
    "\n",
    "#矩阵的上三角/下三角，可指定偏移量\n",
    "print(\"x.triu = \")\n",
    "print(torch.triu(x))\n",
    "print(\"x.tril = \")\n",
    "print(torch.tril(x))\n",
    "\n",
    "#矩阵乘法，batch的矩阵乘法\n",
    "print(\"x * x = \")\n",
    "print(x.mm(x))\n",
    "\n",
    "#转置\n",
    "print(\"x.t = \")\n",
    "print(torch.t(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.3 广播机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2]])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "tensor([[2, 3],\n",
      "        [3, 4],\n",
      "        [4, 5]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(1, 3).view(1, 2)\n",
    "print(x)\n",
    "y = torch.arange(1, 4).view(3, 1)\n",
    "print(y)\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.4 运算的内存开销"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2])\n",
      "tensor([3, 4])\n",
      "140161452039936\n",
      "140161452122832\n",
      "140161452103072\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2])\n",
    "y = torch.tensor([3, 4])\n",
    "print(x)\n",
    "print(y)\n",
    "id_before = id(y)\n",
    "print(id(x))\n",
    "print(id(y))\n",
    "y = y + x\n",
    "print(id(y))\n",
    "print(id(y) == id_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2])\n",
      "tensor([3, 4])\n",
      "140161467007456\n",
      "140161452140176\n",
      "140161452140176\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2])\n",
    "y = torch.tensor([3, 4])\n",
    "print(x)\n",
    "print(y)\n",
    "print(id(x))\n",
    "print(id(y))\n",
    "id_before = id(y)\n",
    "y[:] = y + x\n",
    "print(id(y))\n",
    "print(id(y) == id_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2])\n",
      "tensor([3, 4])\n",
      "140161452402320\n",
      "140161452150368\n",
      "140161452150368\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2])\n",
    "y = torch.tensor([3, 4])\n",
    "print(x)\n",
    "print(y)\n",
    "print(id(x))\n",
    "print(id(y))\n",
    "id_before = id(y)\n",
    "torch.add(x, y, out=y) # y += x, y.add_(x)\n",
    "print(id(y))\n",
    "print(id(y) == id_before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.5 `Tensor`和NumPy相互转换\n",
    "**`numpy()`和`from_numpy()`这两个函数产生的`Tensor`和NumPy array实际是使用的相同的内存，改变其中一个时另一个也会改变！！！**\n",
    "### `Tensor`转NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.]) [1. 1. 1. 1. 1.]\n",
      "tensor([2., 2., 2., 2., 2.]) [2. 2. 2. 2. 2.]\n",
      "tensor([3., 3., 3., 3., 3.]) [3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "b = a.numpy()\n",
    "print(a, b)\n",
    "\n",
    "a += 1\n",
    "print(a, b)\n",
    "b += 1\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy数组转`Tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1.] tensor([1., 1., 1.], dtype=torch.float64)\n",
      "[2. 2. 2.] tensor([2., 2., 2.], dtype=torch.float64)\n",
      "[3. 3. 3.] tensor([3., 3., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(3)\n",
    "b = torch.from_numpy(a)\n",
    "print(a, b)\n",
    "\n",
    "a += 1\n",
    "print(a, b)\n",
    "b += 1\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "直接用`torch.tensor()`将NumPy数组转换成`Tensor`，该方法总是会进行数据拷贝，返回的`Tensor`和原来的数据不再共享内存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4. 4. 4.] tensor([3., 3., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 用torch.tensor()转换时不会共享内存\n",
    "c = torch.tensor(a)\n",
    "a += 1\n",
    "print(a, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.6 `Tensor` on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.7870,  1.1076, -0.0715,  0.8834, -0.0170],\n",
      "        [-0.4453,  0.1922,  2.1975, -0.3700, -1.7575],\n",
      "        [ 0.1676,  1.4900,  1.2908,  1.6442,  4.9300],\n",
      "        [ 0.8756,  1.2953,  3.4197,  2.6456,  0.6913],\n",
      "        [-0.5147,  2.9457, -0.2904, -1.3495, -1.0689]], device='cuda:0')\n",
      "tensor([[ 1.7870,  1.1076, -0.0715,  0.8834, -0.0170],\n",
      "        [-0.4453,  0.1922,  2.1975, -0.3700, -1.7575],\n",
      "        [ 0.1676,  1.4900,  1.2908,  1.6442,  4.9300],\n",
      "        [ 0.8756,  1.2953,  3.4197,  2.6456,  0.6913],\n",
      "        [-0.5147,  2.9457, -0.2904, -1.3495, -1.0689]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 以下代码只有在PyTorch GPU版本上才会执行\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # GPU\n",
    "    y = torch.ones_like(x, device=device)  # 直接创建一个在GPU上的Tensor\n",
    "    x = x.to(device)                       # 等价于 .to(\"cuda\")\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # to()还可以同时更改数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
