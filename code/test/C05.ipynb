{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - 卷积基本知识"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "tensor([[2, 2],\n",
      "        [2, 2]])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "#手动实现一个二维卷积算子，stride为1\n",
    "def corr2d(X, K):  # 本函数已保存在d2lzh_pytorch包中方便以后使用\n",
    "    h, w = K.shape    \n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i: i + h, j: j + w] * K).sum()\n",
    "    return Y\n",
    "\n",
    "\n",
    "# 注意点乘和叉乘的用法\n",
    "a = torch.tensor([[1,1],[1,1]])\n",
    "b = torch.tensor([[1,1],[1,1]])\n",
    "\n",
    "print(a*b)\n",
    "\n",
    "print(a.mm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19., 25.],\n",
       "        [37., 43.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n",
    "K = torch.tensor([[0, 1], [2, 3]])\n",
    "corr2d(X, K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super(Conv2D, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.randn(1))\n",
    "        #print(self.weight.shape)\n",
    "        print(self.weight)\n",
    "        print(self.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return corr2d(x, self.weight) + self.bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1., -1.],\n",
       "        [-1., -1.],\n",
       "        [-1., -1.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = corr2d(X, K)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1., -1.],\n",
      "        [-1., -1.],\n",
      "        [-1., -1.]])\n",
      "Parameter containing:\n",
      "tensor([[-0.5968, -0.7940]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.7691], requires_grad=True)\n",
      "Step 200, loss 0.776\n",
      "Step 400, loss 0.402\n",
      "Step 600, loss 0.208\n",
      "Step 800, loss 0.108\n",
      "Step 1000, loss 0.056\n",
      "Step 1200, loss 0.029\n",
      "Step 1400, loss 0.015\n",
      "Step 1600, loss 0.008\n",
      "Step 1800, loss 0.004\n",
      "Step 2000, loss 0.002\n",
      "Step 2200, loss 0.001\n",
      "Step 2400, loss 0.001\n",
      "Step 2600, loss 0.000\n",
      "Step 2800, loss 0.000\n",
      "Step 3000, loss 0.000\n",
      "Step 3200, loss 0.000\n",
      "Step 3400, loss 0.000\n",
      "Step 3600, loss 0.000\n",
      "Step 3800, loss 0.000\n",
      "Step 4000, loss 0.000\n",
      "Step 4200, loss 0.000\n",
      "Step 4400, loss 0.000\n",
      "Step 4600, loss 0.000\n",
      "Step 4800, loss 0.000\n",
      "Step 5000, loss 0.000\n",
      "Parameter containing:\n",
      "tensor([[ 0.9997, -0.9998]], requires_grad=True) Parameter containing:\n",
      "tensor([-4.2163e-06], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#注意：此处使用的X与原文不一样， 元素并非0或1值， bias的求解结果并不趋于0，除非我们在\n",
    "#     损失函数中主动加上\n",
    "\n",
    "X = torch.tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n",
    "#X = torch.ones(6, 8)\n",
    "#X[:, 2:6] = 0\n",
    "K = torch.tensor([[1, -1]])\n",
    "Y = corr2d(X, K)\n",
    "\n",
    "print(Y)\n",
    "\n",
    "# 构造一个核数组形状是(1, 2)的二维卷积层\n",
    "conv2d = Conv2D(kernel_size=(1, 2))\n",
    "\n",
    "step = 5000\n",
    "lr = 0.001\n",
    "for i in range(step):\n",
    "    Y_hat = conv2d(X)\n",
    "    l = ((Y_hat - Y) ** 2).sum()\n",
    "    l += (conv2d.bias ** 2).sum() * 100\n",
    "    l.backward()\n",
    "\n",
    "    # 梯度下降\n",
    "    conv2d.weight.data -= lr * conv2d.weight.grad\n",
    "    conv2d.bias.data -= lr * conv2d.bias.grad\n",
    "\n",
    "    # 梯度清0\n",
    "    conv2d.weight.grad.fill_(0)\n",
    "    conv2d.bias.grad.fill_(0)\n",
    "    if (i + 1) % 200 == 0:\n",
    "        print('Step %d, loss %.3f' % (i + 1, l.item()))\n",
    "\n",
    "\n",
    "print(conv2d.weight, conv2d.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - 填充与步长"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# 定义一个函数来计算卷积层。它对输入和输出做相应的升维和降维\n",
    "def comp_conv2d(conv2d, X):\n",
    "    # (1, 1)代表批量大小和通道数（“多输入通道和多输出通道”一节将介绍）均为1\n",
    "    X = X.view((1, 1) + X.shape)\n",
    "    Y = conv2d(X)\n",
    "    return Y.view(Y.shape[2:])  # 排除不关心的前两维：批量和通道\n",
    "\n",
    "# 注意这里是两侧分别填充1行或列，所以在两侧一共填充2行或列\n",
    "conv2d = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, padding=1)\n",
    "\n",
    "X = torch.rand(8, 8)\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用高为5、宽为3的卷积核。在高和宽两侧的填充数分别为2和1\n",
    "conv2d = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(5, 3), padding=(2, 1))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1, stride=2)\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(1, 1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - 多输入通道、多输出通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape:  torch.Size([2, 3, 3])\n",
      "K.shape:  torch.Size([2, 2, 2])\n",
      "out.shape:  torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "import d2lzh_pytorch as d2l\n",
    "\n",
    "def corr2d_multi_in(X, K):\n",
    "    # 沿着X和K的第0维（通道维）分别计算再相加\n",
    "    res = d2l.corr2d(X[0, :, :], K[0, :, :])\n",
    "    for i in range(1, X.shape[0]):\n",
    "        res += d2l.corr2d(X[i, :, :], K[i, :, :])\n",
    "    return res\n",
    "\n",
    "\n",
    "X = torch.tensor([[[0, 1, 2], [3, 4, 5], [6, 7, 8]],\n",
    "              [[1, 2, 3], [4, 5, 6], [7, 8, 9]]])\n",
    "K = torch.tensor([[[0, 1], [2, 3]], [[1, 2], [3, 4]]])\n",
    "\n",
    "out = corr2d_multi_in(X, K)\n",
    "\n",
    "## 2通道输入，原始图像为3x3\n",
    "print('X.shape: ', X.size())\n",
    "## 2通道卷积核，尺寸是2x2\n",
    "print('K.shape: ', K.size())\n",
    "## 输出为1通道2x2，因为运算中将不同的输出通道进行了叠加\n",
    "print('out.shape: ', out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 2, 2])\n",
      "torch.Size([3, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "def corr2d_multi_in_out(X, K):\n",
    "    # 对K的第0维遍历，每次同输入X做互相关计算。所有结果使用stack函数合并在一起\n",
    "    return torch.stack([corr2d_multi_in(X, k) for k in K])\n",
    "\n",
    "## conv kernel原为2x2x2的tensor，此处扩展为3x2x2x2的tensor，从而使得\n",
    "## 输出也变为3通道\n",
    "K = torch.stack([K, K + 1, K + 2])\n",
    "print(K.shape) # torch.Size([3, 2, 2, 2])\n",
    "\n",
    "out = corr2d_multi_in_out(X, K)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5403, 0.5927, 0.8335],\n",
      "         [1.0067, 0.1544, 1.0499],\n",
      "         [0.7364, 0.7604, 0.7290]],\n",
      "\n",
      "        [[0.4948, 0.4038, 0.5090],\n",
      "         [0.9144, 0.2914, 1.0752],\n",
      "         [0.9712, 0.4192, 0.7137]]])\n",
      "tensor([[[0.5403, 0.5927, 0.8335],\n",
      "         [1.0067, 0.1544, 1.0499],\n",
      "         [0.7364, 0.7604, 0.7290]],\n",
      "\n",
      "        [[0.4948, 0.4038, 0.5090],\n",
      "         [0.9144, 0.2914, 1.0752],\n",
      "         [0.9712, 0.4192, 0.7137]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def corr2d_multi_in_out_1x1(X, K):\n",
    "    c_i, h, w = X.shape\n",
    "    c_o = K.shape[0]\n",
    "    X = X.view(c_i, h * w)\n",
    "    K = K.view(c_o, c_i)\n",
    "    Y = torch.mm(K, X)  # 全连接层的矩阵乘法\n",
    "    return Y.view(c_o, h, w)\n",
    "\n",
    "X = torch.rand(3, 3, 3)\n",
    "K = torch.rand(2, 3, 1, 1)\n",
    "\n",
    "Y1 = corr2d_multi_in_out_1x1(X, K)\n",
    "Y2 = corr2d_multi_in_out(X, K)\n",
    "\n",
    "print(Y1)\n",
    "print(Y2)\n",
    "\n",
    "(Y1 - Y2).norm().item() < 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - 池化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "tensor([[4., 5.],\n",
      "        [7., 8.]])\n",
      "tensor([[2., 3.],\n",
      "        [5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def pool2d(X, pool_size, mode='max'):\n",
    "    X = X.float()\n",
    "    p_h, p_w = pool_size\n",
    "    Y = torch.zeros(X.shape[0] - p_h + 1, X.shape[1] - p_w + 1)\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == 'max':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].max()\n",
    "            elif mode == 'avg':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()       \n",
    "    return Y\n",
    "\n",
    "X = torch.tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n",
    "print(X)\n",
    "print(pool2d(X, (2, 2)))\n",
    "print(pool2d(X, (2, 2), 'avg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.]],\n",
       "\n",
       "         [[ 1.,  2.,  3.,  4.],\n",
       "          [ 5.,  6.,  7.,  8.],\n",
       "          [ 9., 10., 11., 12.],\n",
       "          [13., 14., 15., 16.]]]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(16, dtype=torch.float).view((1, 1, 4, 4))\n",
    "\n",
    "X = torch.cat((X, X + 1), dim=1)\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]],\n",
       "\n",
       "         [[ 6.,  8.],\n",
       "          [14., 16.]]]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
    "pool2d(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5 - LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LeNet](https://engmrk.com/wp-content/uploads/2018/09/LeNet_Original_Image.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we will use cpu to do training and inference\n",
      "Sequential(\n",
      "  (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (1): Sigmoid()\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (4): Sigmoid()\n",
      "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (6): Flatten()\n",
      "  (7): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (8): Sigmoid()\n",
      "  (9): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (10): Sigmoid()\n",
      "  (11): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "import d2lzh_pytorch as d2l\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('we will use', device, 'to do training and inference')\n",
    "\n",
    "# the tutorial create a new class based on nn.Module, but here to make it simple, we use nn.Sequential\n",
    "LeNet = nn.Sequential(\n",
    "        ##注意，此处输入为1 x 28 x 28的图像（1通道）\n",
    "        nn.Conv2d(1, 6, 5), # in_channels, out_channels, kernel_size\n",
    "        nn.Sigmoid(),\n",
    "        ##conv1输出为6 x 24 x 24\n",
    "        nn.MaxPool2d(2, 2), # kernel_size, stride\n",
    "        ##maxpool1输出为6 x 12 x 12\n",
    "        nn.Conv2d(6, 16, 5),\n",
    "        ##conv2输出为16 x 8 x 8\n",
    "        nn.Sigmoid(),\n",
    "        nn.MaxPool2d(2, 2),\n",
    "        ##maxpool2输出为16 x 4 x 4\n",
    "        #below is fc\n",
    "        nn.Flatten(),\n",
    "        ## 所以下面是16*4*4，如果输入是32x32的图片，那么下面就得变为16*5*5\n",
    "        nn.Linear(16*4*4, 120),\n",
    "        nn.Sigmoid(),\n",
    "        nn.Linear(120, 84),\n",
    "        nn.Sigmoid(),\n",
    "        nn.Linear(84, 10), \n",
    "        )\n",
    "\n",
    "#input: torch.Size([256, 1, 28, 28])\n",
    "#conv1+maxpool1: torch.Size([256, 6, 12, 12])\n",
    "#conv2+maxpool2: torch.Size([256, 16, 4, 4])\n",
    "#flatten: torch.Size([256, 256])\n",
    "#fc1: torch.Size([256, 120])\n",
    "#fc2: torch.Size([256, 84])\n",
    "#fc3: torch.Size([256, 10])\n",
    "\n",
    "   \n",
    "    \n",
    "\n",
    "    \n",
    "### 下面是另一种写法    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        nn.Module.__init__(self)\n",
    "        #卷积层\n",
    "        self.conv1=nn.Conv2d(1,6,5)\n",
    "        self.conv2=nn.Conv2d(6,16,5)\n",
    "        #全连接层\n",
    "        ### \n",
    "        self.fc1 = nn.Linear(16*4*4,120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #conv-relu-pooling\n",
    "        print('input:', x.shape)\n",
    "        x=F.max_pool2d(F.relu(self.conv1(x)),(2,2))\n",
    "        print('conv1+maxpool1:', x.shape)\n",
    "        x=F.max_pool2d(F.relu(self.conv2(x)),2)\n",
    "        print('conv2+maxpool2:', x.shape)\n",
    "        #reshape\n",
    "        x=x.view(x.size()[0],-1)\n",
    "        print('flatten:', x.shape)\n",
    "        x=F.relu(self.fc1(x))\n",
    "        print('fc1:', x.shape)\n",
    "        x=F.relu(self.fc2(x))\n",
    "        print('fc2:', x.shape)\n",
    "        x=self.fc3(x)\n",
    "        print('fc3:', x.shape)\n",
    "        return x\n",
    "\n",
    "net = LeNet\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)\n",
    "\n",
    "# 本函数已保存在d2lzh_pytorch包中方便以后使用。该函数将被逐步改进。\n",
    "def evaluate_accuracy(data_iter, net, device=None):\n",
    "    if device is None and isinstance(net, torch.nn.Module):\n",
    "        # 如果没指定device就使用net的device\n",
    "        device = list(net.parameters())[0].device\n",
    "    acc_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(net, torch.nn.Module):\n",
    "                net.eval() # 评估模式, 这会关闭dropout\n",
    "                acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
    "                net.train() # 改回训练模式\n",
    "            else: # 自定义的模型, 3.13节之后不会用到, 不考虑GPU\n",
    "                if('is_training' in net.__code__.co_varnames): # 如果有is_training这个参数\n",
    "                    # 将is_training设置成False\n",
    "                    acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() \n",
    "                else:\n",
    "                    acc_sum += (net(X).argmax(dim=1) == y).float().sum().item() \n",
    "            n += y.shape[0]\n",
    "    return acc_sum / n\n",
    "\n",
    "# 本函数已保存在d2lzh_pytorch包中方便以后使用\n",
    "def train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs):\n",
    "    net = net.to(device)\n",
    "    print(\"training on \", device)\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, batch_count, start = 0.0, 0.0, 0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            # data to dedicate device, it's important\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_l_sum += l.cpu().item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n",
    "            n += y.shape[0]\n",
    "            batch_count += 1\n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cpu\n",
      "epoch 1, loss 1.0611, train acc 0.591, test acc 0.721, time 10.4 sec\n",
      "epoch 2, loss 0.5409, train acc 0.788, test acc 0.807, time 10.2 sec\n",
      "epoch 3, loss 0.4315, train acc 0.836, test acc 0.843, time 10.2 sec\n",
      "epoch 4, loss 0.3744, train acc 0.860, test acc 0.863, time 10.3 sec\n",
      "epoch 5, loss 0.3381, train acc 0.873, test acc 0.868, time 10.3 sec\n",
      "epoch 6, loss 0.3133, train acc 0.883, test acc 0.868, time 10.2 sec\n",
      "epoch 7, loss 0.3016, train acc 0.887, test acc 0.877, time 10.3 sec\n",
      "epoch 8, loss 0.2817, train acc 0.895, test acc 0.876, time 10.3 sec\n",
      "epoch 9, loss 0.2757, train acc 0.897, test acc 0.870, time 10.3 sec\n",
      "epoch 10, loss 0.2627, train acc 0.901, test acc 0.889, time 10.4 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.01, 10\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6 - AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (4): ReLU()\n",
      "  (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (7): ReLU()\n",
      "  (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (9): ReLU()\n",
      "  (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU()\n",
      "  (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (13): Flatten()\n",
      "  (14): Linear(in_features=6400, out_features=4096, bias=True)\n",
      "  (15): ReLU()\n",
      "  (16): Dropout(p=0.5, inplace=False)\n",
      "  (17): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (18): ReLU()\n",
      "  (19): Dropout(p=0.5, inplace=False)\n",
      "  (20): Linear(in_features=4096, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "import d2lzh_pytorch as d2l\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "'''\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 96, 11, 4), # in_channels, out_channels, kernel_size, stride, padding\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2), # kernel_size, stride\n",
    "            # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数\n",
    "            nn.Conv2d(96, 256, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2),\n",
    "            # 连续3个卷积层，且使用更小的卷积窗口。除了最后的卷积层外，进一步增大了输出通道数。\n",
    "            # 前两个卷积层后不使用池化层来减小输入的高和宽\n",
    "            nn.Conv2d(256, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2)\n",
    "        )\n",
    "         # 这里全连接层的输出个数比LeNet中的大数倍。使用丢弃层来缓解过拟合\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256*5*5, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            # 输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000\n",
    "            nn.Linear(4096, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        feature = self.conv(img)\n",
    "        output = self.fc(feature.view(img.shape[0], -1))\n",
    "        return output\n",
    "'''\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "AlexNet = nn.Sequential(\n",
    "            ### convolution part\n",
    "            nn.Conv2d(1, 96, 11, 4), # in_channels, out_channels, kernel_size, stride, padding\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2), # kernel_size, stride\n",
    "            # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数\n",
    "            nn.Conv2d(96, 256, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2),\n",
    "            # 连续3个卷积层，且使用更小的卷积窗口。除了最后的卷积层外，进一步增大了输出通道数。\n",
    "            # 前两个卷积层后不使用池化层来减小输入的高和宽\n",
    "            nn.Conv2d(256, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2),\n",
    "\n",
    "            ### full connection layers\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256*5*5, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            # 输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000\n",
    "            nn.Linear(4096, 10)\n",
    "            )\n",
    "\n",
    "\n",
    "net = AlexNet\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本函数已保存在d2lzh_pytorch包中方便以后使用\n",
    "def load_data_fashion_mnist(batch_size, resize=None, root='~/Datasets/FashionMNIST'):\n",
    "    \"\"\"Download the fashion mnist dataset and then load into memory.\"\"\"\n",
    "    trans = []\n",
    "    if resize:\n",
    "        trans.append(torchvision.transforms.Resize(size=resize))\n",
    "    trans.append(torchvision.transforms.ToTensor())\n",
    "\n",
    "    transform = torchvision.transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True, download=True, transform=transform)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False, download=True, transform=transform)\n",
    "\n",
    "    train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    return train_iter, test_iter\n",
    "\n",
    "batch_size = 256\n",
    "# 如出现“out of memory”的报错信息，可减小batch_size或resize\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=224)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 0.2136, train acc 0.922, test acc 0.908, time 69.2 sec\n",
      "epoch 2, loss 0.1928, train acc 0.928, test acc 0.917, time 69.1 sec\n",
      "epoch 3, loss 0.1782, train acc 0.933, test acc 0.911, time 69.0 sec\n",
      "epoch 4, loss 0.1652, train acc 0.938, test acc 0.918, time 70.5 sec\n",
      "epoch 5, loss 0.1526, train acc 0.943, test acc 0.922, time 69.8 sec\n"
     ]
    }
   ],
   "source": [
    "net = AlexNet\n",
    "#print(net)\n",
    "lr, num_epochs = 0.001, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7 - VGG net\n",
    "\n",
    "#### 经典VGG网络架构\n",
    "![VGG](https://pic4.zhimg.com/80/v2-ea924e733676e0da534f677a97c98653_720w.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "import d2lzh_pytorch as d2l\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def vgg_block(num_convs, in_channels, out_channels):\n",
    "    blk = []\n",
    "    for i in range(num_convs):\n",
    "        if i == 0:\n",
    "            blk.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "        else:\n",
    "            blk.append(nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        blk.append(nn.ReLU())\n",
    "    blk.append(nn.MaxPool2d(kernel_size=2, stride=2)) # 这里会使宽高减半\n",
    "    return nn.Sequential(*blk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg_block_1 output shape:  torch.Size([1, 64, 112, 112])\n",
      "vgg_block_2 output shape:  torch.Size([1, 128, 56, 56])\n",
      "vgg_block_3 output shape:  torch.Size([1, 256, 28, 28])\n",
      "vgg_block_4 output shape:  torch.Size([1, 512, 14, 14])\n",
      "vgg_block_5 output shape:  torch.Size([1, 512, 7, 7])\n",
      "fc output shape:  torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "## 下面实现的是VGG-11网络\n",
    "conv_arch_11 = ((1, 1, 64), (1, 64, 128), (2, 128, 256), (2, 256, 512), (2, 512, 512))\n",
    "# 经过5个vgg_block, 宽高会减半5次, 变成 224/32 = 7\n",
    "fc_features = 512 * 7 * 7 # c * w * h\n",
    "fc_hidden_units = 4096 # 任意\n",
    "\n",
    "def vgg(conv_arch, fc_features, fc_hidden_units=4096):\n",
    "    net = nn.Sequential()\n",
    "    # 卷积层部分\n",
    "    for i, (num_convs, in_channels, out_channels) in enumerate(conv_arch):\n",
    "        # 每经过一个vgg_block都会使宽高减半\n",
    "        net.add_module(\"vgg_block_\" + str(i+1), vgg_block(num_convs, in_channels, out_channels))\n",
    "    # 全连接层部分\n",
    "    net.add_module(\"fc\", nn.Sequential(d2l.FlattenLayer(),\n",
    "                                 nn.Linear(fc_features, fc_hidden_units),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.5),\n",
    "                                 nn.Linear(fc_hidden_units, fc_hidden_units),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.5),\n",
    "                                 nn.Linear(fc_hidden_units, 10)\n",
    "                                ))\n",
    "    return net\n",
    "\n",
    "\n",
    "net = vgg(conv_arch_11, fc_features, fc_hidden_units)\n",
    "X = torch.rand(1, 1, 224, 224)\n",
    "\n",
    "# named_children获取一级子模块及其名字(named_modules会返回所有子模块,包括子模块的子模块)\n",
    "for name, blk in net.named_children(): \n",
    "    X = blk(X)\n",
    "    print(name, 'output shape: ', X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (vgg_block_1): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (vgg_block_2): Sequential(\n",
      "    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (vgg_block_3): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (vgg_block_4): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (vgg_block_5): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): FlattenLayer()\n",
      "    (1): Linear(in_features=3136, out_features=512, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Dropout(p=0.5, inplace=False)\n",
      "    (7): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "ratio = 8\n",
    "small_conv_arch = [(1, 1, 64//ratio), (1, 64//ratio, 128//ratio), (2, 128//ratio, 256//ratio), \n",
    "                   (2, 256//ratio, 512//ratio), (2, 512//ratio, 512//ratio)]\n",
    "net = vgg(small_conv_arch, fc_features // ratio, fc_hidden_units // ratio)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 0.5524, train acc 0.795, test acc 0.873, time 73.9 sec\n",
      "epoch 2, loss 0.3217, train acc 0.882, test acc 0.893, time 74.4 sec\n",
      "epoch 3, loss 0.2755, train acc 0.899, test acc 0.905, time 74.9 sec\n",
      "epoch 4, loss 0.2438, train acc 0.911, test acc 0.913, time 74.5 sec\n",
      "epoch 5, loss 0.2218, train acc 0.918, test acc 0.913, time 74.7 sec\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "# 如出现“out of memory”的报错信息，可减小batch_size或resize\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)\n",
    "\n",
    "lr, num_epochs = 0.001, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VGG16\n",
    "![vgg16](https://neurohive.io/wp-content/uploads/2018/11/vgg16-1-e1542731207177.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 0.7652, train acc 0.709, test acc 0.874, time 130.2 sec\n",
      "epoch 2, loss 0.3250, train acc 0.883, test acc 0.894, time 130.5 sec\n",
      "epoch 3, loss 0.2815, train acc 0.898, test acc 0.908, time 128.1 sec\n",
      "epoch 4, loss 0.2507, train acc 0.910, test acc 0.903, time 132.8 sec\n",
      "epoch 5, loss 0.2321, train acc 0.916, test acc 0.911, time 134.3 sec\n"
     ]
    }
   ],
   "source": [
    "## 下面实现的是VGG-16网络\n",
    "conv_arch_16 = ((2, 1, 64), (2, 64, 128), (3, 128, 256), (3, 256, 512), (3, 512, 512))\n",
    "\n",
    "\n",
    "ratio = 8\n",
    "small_conv_arch_16 = [(2, 1, 64//ratio), (2, 64//ratio, 128//ratio), (3, 128//ratio, 256//ratio), \n",
    "                   (3, 256//ratio, 512//ratio), (3, 512//ratio, 512//ratio)]\n",
    "net = vgg(small_conv_arch_16, fc_features // ratio, fc_hidden_units // ratio)\n",
    "\n",
    "batch_size = 64\n",
    "# 如出现“out of memory”的报错信息，可减小batch_size或resize\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)\n",
    "\n",
    "lr, num_epochs = 0.001, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![vgg19](https://miro.medium.com/max/700/1*Q_bg1E3trWcjdk9_jnVGwg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 2.3032, train acc 0.097, test acc 0.100, time 142.9 sec\n",
      "epoch 2, loss 2.3029, train acc 0.100, test acc 0.100, time 142.7 sec\n",
      "epoch 3, loss 2.3028, train acc 0.100, test acc 0.100, time 142.7 sec\n",
      "epoch 4, loss 2.3028, train acc 0.099, test acc 0.100, time 142.9 sec\n",
      "epoch 5, loss 2.3028, train acc 0.097, test acc 0.100, time 142.9 sec\n"
     ]
    }
   ],
   "source": [
    "## 下面实现的是VGG-19网络\n",
    "conv_arch_19 = ((2, 1, 64), (2, 64, 128), (4, 128, 256), (4, 256, 512), (4, 512, 512))\n",
    "\n",
    "\n",
    "ratio = 8\n",
    "small_conv_arch_19 = [(2, 1, 64//ratio), (2, 64//ratio, 128//ratio), (4, 128//ratio, 256//ratio), \n",
    "                   (4, 256//ratio, 512//ratio), (4, 512//ratio, 512//ratio)]\n",
    "net = vgg(small_conv_arch_19, fc_features // ratio, fc_hidden_units // ratio)\n",
    "\n",
    "batch_size = 64\n",
    "# 如出现“out of memory”的报错信息，可减小batch_size或resize\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)\n",
    "\n",
    "lr, num_epochs = 0.001, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8 - NiN 网中网"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "import d2lzh_pytorch as d2l\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NiN块\n",
    "##### 一个常规卷积跟两个1x1卷积层（相当于两个全连接层）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nin_block(in_channels, out_channels, kernel_size, stride, padding):\n",
    "    blk = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Conv2d(out_channels, out_channels, kernel_size=1),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Conv2d(out_channels, out_channels, kernel_size=1),\n",
    "                        nn.ReLU())\n",
    "    return blk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NiN 网络\n",
    "##### 基于AlexNet的参考设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 output shape:  torch.Size([1, 96, 54, 54])\n",
      "1 output shape:  torch.Size([1, 96, 26, 26])\n",
      "2 output shape:  torch.Size([1, 256, 26, 26])\n",
      "3 output shape:  torch.Size([1, 256, 12, 12])\n",
      "4 output shape:  torch.Size([1, 384, 12, 12])\n",
      "5 output shape:  torch.Size([1, 384, 5, 5])\n",
      "6 output shape:  torch.Size([1, 384, 5, 5])\n",
      "7 output shape:  torch.Size([1, 10, 5, 5])\n",
      "8 output shape:  torch.Size([1, 10, 1, 1])\n",
      "9 output shape:  torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "# 已保存在d2lzh_pytorch\n",
    "import torch.nn.functional as F\n",
    "class GlobalAvgPool2d(nn.Module):\n",
    "    # 全局平均池化层可通过将池化窗口形状设置成输入的高和宽实现\n",
    "    def __init__(self):\n",
    "        super(GlobalAvgPool2d, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return F.avg_pool2d(x, kernel_size=x.size()[2:])\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nin_block(1, 96, kernel_size=11, stride=4, padding=0),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    nin_block(96, 256, kernel_size=5, stride=1, padding=2),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    nin_block(256, 384, kernel_size=3, stride=1, padding=1),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2), \n",
    "    nn.Dropout(0.5),\n",
    "    # 标签类别数是10\n",
    "    nin_block(384, 10, kernel_size=3, stride=1, padding=1),\n",
    "    GlobalAvgPool2d(), \n",
    "    # 将四维的输出转成二维的输出，其形状为(批量大小, 10)\n",
    "    d2l.FlattenLayer()\n",
    "    )\n",
    "\n",
    "X = torch.rand(1, 1, 224, 224)\n",
    "for name, blk in net.named_children(): \n",
    "    X = blk(X)\n",
    "    print(name, 'output shape: ', X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 1.1336, train acc 0.576, test acc 0.758, time 98.8 sec\n",
      "epoch 2, loss 0.5638, train acc 0.795, test acc 0.819, time 98.5 sec\n",
      "epoch 3, loss 0.4701, train acc 0.828, test acc 0.833, time 99.0 sec\n",
      "epoch 4, loss 0.4211, train acc 0.843, test acc 0.846, time 99.0 sec\n",
      "epoch 5, loss 0.3906, train acc 0.855, test acc 0.860, time 99.4 sec\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "# 如出现“out of memory”的报错信息，可减小batch_size或resize\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)\n",
    "\n",
    "lr, num_epochs = 0.002, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9 - GoogLeNet\n",
    "#### 名字有LeNet，但实际上跟LeNet已毫无关系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inception Block\n",
    "![Inception Block](http://192.168.1.168:3030/img/chapter05/5.9_inception.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "import d2lzh_pytorch as d2l\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Inception(nn.Module):\n",
    "    # c1 - c4为每条线路里的层的输出通道数\n",
    "    def __init__(self, in_c, c1, c2, c3, c4):\n",
    "        super(Inception, self).__init__()\n",
    "        # 线路1，单1 x 1卷积层\n",
    "        self.p1_1 = nn.Conv2d(in_c, c1, kernel_size=1)\n",
    "        # 线路2，1 x 1卷积层后接3 x 3卷积层\n",
    "        self.p2_1 = nn.Conv2d(in_c, c2[0], kernel_size=1)\n",
    "        self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)\n",
    "        # 线路3，1 x 1卷积层后接5 x 5卷积层\n",
    "        self.p3_1 = nn.Conv2d(in_c, c3[0], kernel_size=1)\n",
    "        self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2)\n",
    "        # 线路4，3 x 3最大池化层后接1 x 1卷积层\n",
    "        self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.p4_2 = nn.Conv2d(in_c, c4, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        p1 = F.relu(self.p1_1(x))\n",
    "        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))\n",
    "        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))\n",
    "        p4 = F.relu(self.p4_2(self.p4_1(x)))\n",
    "        return torch.cat((p1, p2, p3, p4), dim=1)  # 在通道维上连结输出\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "                   nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1),\n",
    "                   nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b3 = nn.Sequential(Inception(192, 64, (96, 128), (16, 32), 32),\n",
    "                   Inception(256, 128, (128, 192), (32, 96), 64),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b4 = nn.Sequential(Inception(480, 192, (96, 208), (16, 48), 64),\n",
    "                   Inception(512, 160, (112, 224), (24, 64), 64),\n",
    "                   Inception(512, 128, (128, 256), (24, 64), 64),\n",
    "                   Inception(512, 112, (144, 288), (32, 64), 64),\n",
    "                   Inception(528, 256, (160, 320), (32, 128), 128),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b5 = nn.Sequential(Inception(832, 256, (160, 320), (32, 128), 128),\n",
    "                   Inception(832, 384, (192, 384), (48, 128), 128),\n",
    "                   d2l.GlobalAvgPool2d())\n",
    "\n",
    "net = nn.Sequential(b1, b2, b3, b4, b5, \n",
    "                    d2l.FlattenLayer(), nn.Linear(1024, 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape:  torch.Size([1, 64, 24, 24])\n",
      "output shape:  torch.Size([1, 192, 12, 12])\n",
      "output shape:  torch.Size([1, 480, 6, 6])\n",
      "output shape:  torch.Size([1, 832, 3, 3])\n",
      "output shape:  torch.Size([1, 1024, 1, 1])\n",
      "output shape:  torch.Size([1, 1024])\n",
      "output shape:  torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "#net = nn.Sequential(b1, b2, b3, b4, b5, d2l.FlattenLayer(), nn.Linear(1024, 10))\n",
    "X = torch.rand(1, 1, 96, 96)\n",
    "for blk in net.children(): \n",
    "    X = blk(X)\n",
    "    print('output shape: ', X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 1.0632, train acc 0.578, test acc 0.811, time 70.8 sec\n",
      "epoch 2, loss 0.4310, train acc 0.842, test acc 0.862, time 71.1 sec\n",
      "epoch 3, loss 0.3480, train acc 0.871, test acc 0.859, time 71.4 sec\n",
      "epoch 4, loss 0.3042, train acc 0.887, test acc 0.871, time 71.7 sec\n",
      "epoch 5, loss 0.2744, train acc 0.898, test acc 0.891, time 72.7 sec\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "# 如出现“out of memory”的报错信息，可减小batch_size或resize\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96)\n",
    "\n",
    "lr, num_epochs = 0.001, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 10 - BN(Batch Norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "import d2lzh_pytorch as d2l\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def batch_norm(is_training, X, gamma, beta, moving_mean, moving_var, eps, momentum):\n",
    "    # 判断当前模式是训练模式还是预测模式\n",
    "    if not is_training:\n",
    "        # 如果是在预测模式下，直接使用传入的移动平均所得的均值和方差\n",
    "        X_hat = (X - moving_mean) / torch.sqrt(moving_var + eps)\n",
    "    else:\n",
    "        assert len(X.shape) in (2, 4)\n",
    "        if len(X.shape) == 2:\n",
    "            # 使用全连接层的情况，计算特征维上的均值和方差\n",
    "            mean = X.mean(dim=0)\n",
    "            var = ((X - mean) ** 2).mean(dim=0)\n",
    "        else:\n",
    "            # 使用二维卷积层的情况，计算通道维上（axis=1）的均值和方差。这里我们需要保持\n",
    "            # X的形状以便后面可以做广播运算\n",
    "            mean = X.mean(dim=0, keepdim=True).mean(dim=2, keepdim=True).mean(dim=3, keepdim=True)\n",
    "            var = ((X - mean) ** 2).mean(dim=0, keepdim=True).mean(dim=2, keepdim=True).mean(dim=3, keepdim=True)\n",
    "        # 训练模式下用当前的均值和方差做标准化\n",
    "        X_hat = (X - mean) / torch.sqrt(var + eps)\n",
    "        # 更新移动平均的均值和方差\n",
    "        moving_mean = momentum * moving_mean + (1.0 - momentum) * mean\n",
    "        moving_var = momentum * moving_var + (1.0 - momentum) * var\n",
    "    Y = gamma * X_hat + beta  # 拉伸和偏移\n",
    "    return Y, moving_mean, moving_var\n",
    "\n",
    "\n",
    "\n",
    "class BatchNorm(nn.Module):\n",
    "    def __init__(self, num_features, num_dims):\n",
    "        super(BatchNorm, self).__init__()\n",
    "        if num_dims == 2:\n",
    "            shape = (1, num_features)\n",
    "        else:\n",
    "            shape = (1, num_features, 1, 1)\n",
    "        # 参与求梯度和迭代的拉伸和偏移参数，分别初始化成0和1\n",
    "        self.gamma = nn.Parameter(torch.ones(shape))\n",
    "        self.beta = nn.Parameter(torch.zeros(shape))\n",
    "        # 不参与求梯度和迭代的变量，全在内存上初始化成0\n",
    "        self.moving_mean = torch.zeros(shape)\n",
    "        self.moving_var = torch.zeros(shape)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # 如果X不在内存上，将moving_mean和moving_var复制到X所在显存上\n",
    "        if self.moving_mean.device != X.device:\n",
    "            self.moving_mean = self.moving_mean.to(X.device)\n",
    "            self.moving_var = self.moving_var.to(X.device)\n",
    "        # 保存更新过的moving_mean和moving_var, Module实例的traning属性默认为true, 调用.eval()后设成false\n",
    "        Y, self.moving_mean, self.moving_var = batch_norm(self.training, \n",
    "            X, self.gamma, self.beta, self.moving_mean,\n",
    "            self.moving_var, eps=1e-5, momentum=0.9)\n",
    "        return Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 5), # in_channels, out_channels, kernel_size\n",
    "            BatchNorm(6, num_dims=4),\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(2, 2), # kernel_size, stride\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            BatchNorm(16, num_dims=4),\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            d2l.FlattenLayer(),\n",
    "            nn.Linear(16*4*4, 120),\n",
    "            BatchNorm(120, num_dims=2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(120, 84),\n",
    "            BatchNorm(84, num_dims=2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(84, 10)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 0.9734, train acc 0.794, test acc 0.838, time 2.4 sec\n",
      "epoch 2, loss 0.4532, train acc 0.864, test acc 0.831, time 2.3 sec\n",
      "epoch 3, loss 0.3649, train acc 0.879, test acc 0.844, time 2.4 sec\n",
      "epoch 4, loss 0.3299, train acc 0.887, test acc 0.831, time 2.2 sec\n",
      "epoch 5, loss 0.3064, train acc 0.894, test acc 0.832, time 2.2 sec\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)\n",
    "\n",
    "lr, num_epochs = 0.001, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.1648, 0.9687, 1.1412, 1.0082, 1.0293, 1.0139], device='cuda:0',\n",
       "        grad_fn=<ViewBackward>),\n",
       " tensor([ 0.3200, -0.4523,  0.3891, -0.6843,  0.0520, -0.2863], device='cuda:0',\n",
       "        grad_fn=<ViewBackward>))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[1].gamma.view((-1,)), net[1].beta.view((-1,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 5), # in_channels, out_channels, kernel_size\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(2, 2), # kernel_size, stride\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            d2l.FlattenLayer(),\n",
    "            nn.Linear(16*4*4, 120),\n",
    "            nn.BatchNorm1d(120),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.BatchNorm1d(84),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(84, 10)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 0.9928, train acc 0.791, test acc 0.836, time 1.6 sec\n",
      "epoch 2, loss 0.4536, train acc 0.865, test acc 0.854, time 1.7 sec\n",
      "epoch 3, loss 0.3669, train acc 0.878, test acc 0.820, time 1.7 sec\n",
      "epoch 4, loss 0.3298, train acc 0.887, test acc 0.858, time 1.7 sec\n",
      "epoch 5, loss 0.3107, train acc 0.892, test acc 0.874, time 1.7 sec\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)\n",
    "\n",
    "lr, num_epochs = 0.001, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 11 - ResNet 残差网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 8, 8])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "import d2lzh_pytorch as d2l\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Residual(nn.Module):  # 本类已保存在d2lzh_pytorch包中方便以后使用\n",
    "    def __init__(self, in_channels, out_channels, use_1x1conv=False, stride=1):\n",
    "        super(Residual, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        return F.relu(Y + X)\n",
    "\n",
    "    \n",
    "blk = Residual(3, 3)\n",
    "X = torch.rand((4, 3, 6, 6))\n",
    "blk(X).shape # torch.Size([4, 3, 6, 6])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet-18\n",
    "\n",
    ".   \n",
    ".\n",
    "\n",
    "![resnet18](https://www.researchgate.net/profile/Paolo_Napoletano/publication/322476121/figure/tbl1/AS:668726449946625@1536448218498/ResNet-18-Architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "        nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "        nn.BatchNorm2d(64), \n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "\n",
    "def resnet_block(in_channels, out_channels, num_residuals, first_block=False):\n",
    "    if first_block:\n",
    "        assert in_channels == out_channels # 第一个模块的通道数同输入通道数一致\n",
    "    blk = []\n",
    "    for i in range(num_residuals):\n",
    "        if i == 0 and not first_block:\n",
    "            blk.append(Residual(in_channels, out_channels, use_1x1conv=True, stride=2))\n",
    "        else:\n",
    "            blk.append(Residual(out_channels, out_channels))\n",
    "    return nn.Sequential(*blk)\n",
    "\n",
    "net.add_module(\"resnet_block1\", resnet_block(64, 64, 2, first_block=True))\n",
    "net.add_module(\"resnet_block2\", resnet_block(64, 128, 2))\n",
    "net.add_module(\"resnet_block3\", resnet_block(128, 256, 2))\n",
    "net.add_module(\"resnet_block4\", resnet_block(256, 512, 2))\n",
    "\n",
    "net.add_module(\"global_avg_pool\", d2l.GlobalAvgPool2d()) # GlobalAvgPool2d的输出: (Batch, 512, 1, 1)\n",
    "net.add_module(\"fc\", nn.Sequential(d2l.FlattenLayer(), nn.Linear(512, 10))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  output shape:\t torch.Size([1, 64, 112, 112])\n",
      "1  output shape:\t torch.Size([1, 64, 112, 112])\n",
      "2  output shape:\t torch.Size([1, 64, 112, 112])\n",
      "3  output shape:\t torch.Size([1, 64, 56, 56])\n",
      "resnet_block1  output shape:\t torch.Size([1, 64, 56, 56])\n",
      "resnet_block2  output shape:\t torch.Size([1, 128, 28, 28])\n",
      "resnet_block3  output shape:\t torch.Size([1, 256, 14, 14])\n",
      "resnet_block4  output shape:\t torch.Size([1, 512, 7, 7])\n",
      "global_avg_pool  output shape:\t torch.Size([1, 512, 1, 1])\n",
      "fc  output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand((1, 1, 224, 224))\n",
    "for name, layer in net.named_children():\n",
    "    X = layer(X)\n",
    "    print(name, ' output shape:\\t', X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 0.4146, train acc 0.846, test acc 0.874, time 58.0 sec\n",
      "epoch 2, loss 0.2568, train acc 0.906, test acc 0.889, time 58.2 sec\n",
      "epoch 3, loss 0.2121, train acc 0.922, test acc 0.898, time 58.7 sec\n",
      "epoch 4, loss 0.1824, train acc 0.932, test acc 0.886, time 58.6 sec\n",
      "epoch 5, loss 0.1613, train acc 0.941, test acc 0.880, time 58.6 sec\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "# 如出现“out of memory”的报错信息，可减小batch_size或resize\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96)\n",
    "\n",
    "lr, num_epochs = 0.001, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 12 - DenseNet, 稠密连接网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DenseNet](https://miro.medium.com/max/700/1*RUiMzddMbQ0rx_CCqT2k8Q.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
