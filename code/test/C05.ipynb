{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - 卷积基本知识"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "tensor([[2, 2],\n",
      "        [2, 2]])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "#手动实现一个二维卷积算子，stride为1\n",
    "def corr2d(X, K):  # 本函数已保存在d2lzh_pytorch包中方便以后使用\n",
    "    h, w = K.shape    \n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i: i + h, j: j + w] * K).sum()\n",
    "    return Y\n",
    "\n",
    "\n",
    "# 注意点乘和叉乘的用法\n",
    "a = torch.tensor([[1,1],[1,1]])\n",
    "b = torch.tensor([[1,1],[1,1]])\n",
    "\n",
    "print(a*b)\n",
    "\n",
    "print(a.mm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19., 25.],\n",
       "        [37., 43.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n",
    "K = torch.tensor([[0, 1], [2, 3]])\n",
    "corr2d(X, K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super(Conv2D, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.randn(1))\n",
    "        #print(self.weight.shape)\n",
    "        print(self.weight)\n",
    "        print(self.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return corr2d(x, self.weight) + self.bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1., -1.],\n",
       "        [-1., -1.],\n",
       "        [-1., -1.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = corr2d(X, K)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1., -1.],\n",
      "        [-1., -1.],\n",
      "        [-1., -1.]])\n",
      "Parameter containing:\n",
      "tensor([[-0.5968, -0.7940]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.7691], requires_grad=True)\n",
      "Step 200, loss 0.776\n",
      "Step 400, loss 0.402\n",
      "Step 600, loss 0.208\n",
      "Step 800, loss 0.108\n",
      "Step 1000, loss 0.056\n",
      "Step 1200, loss 0.029\n",
      "Step 1400, loss 0.015\n",
      "Step 1600, loss 0.008\n",
      "Step 1800, loss 0.004\n",
      "Step 2000, loss 0.002\n",
      "Step 2200, loss 0.001\n",
      "Step 2400, loss 0.001\n",
      "Step 2600, loss 0.000\n",
      "Step 2800, loss 0.000\n",
      "Step 3000, loss 0.000\n",
      "Step 3200, loss 0.000\n",
      "Step 3400, loss 0.000\n",
      "Step 3600, loss 0.000\n",
      "Step 3800, loss 0.000\n",
      "Step 4000, loss 0.000\n",
      "Step 4200, loss 0.000\n",
      "Step 4400, loss 0.000\n",
      "Step 4600, loss 0.000\n",
      "Step 4800, loss 0.000\n",
      "Step 5000, loss 0.000\n",
      "Parameter containing:\n",
      "tensor([[ 0.9997, -0.9998]], requires_grad=True) Parameter containing:\n",
      "tensor([-4.2163e-06], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#注意：此处使用的X与原文不一样， 元素并非0或1值， bias的求解结果并不趋于0，除非我们在\n",
    "#     损失函数中主动加上\n",
    "\n",
    "X = torch.tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n",
    "#X = torch.ones(6, 8)\n",
    "#X[:, 2:6] = 0\n",
    "K = torch.tensor([[1, -1]])\n",
    "Y = corr2d(X, K)\n",
    "\n",
    "print(Y)\n",
    "\n",
    "# 构造一个核数组形状是(1, 2)的二维卷积层\n",
    "conv2d = Conv2D(kernel_size=(1, 2))\n",
    "\n",
    "step = 5000\n",
    "lr = 0.001\n",
    "for i in range(step):\n",
    "    Y_hat = conv2d(X)\n",
    "    l = ((Y_hat - Y) ** 2).sum()\n",
    "    l += (conv2d.bias ** 2).sum() * 100\n",
    "    l.backward()\n",
    "\n",
    "    # 梯度下降\n",
    "    conv2d.weight.data -= lr * conv2d.weight.grad\n",
    "    conv2d.bias.data -= lr * conv2d.bias.grad\n",
    "\n",
    "    # 梯度清0\n",
    "    conv2d.weight.grad.fill_(0)\n",
    "    conv2d.bias.grad.fill_(0)\n",
    "    if (i + 1) % 200 == 0:\n",
    "        print('Step %d, loss %.3f' % (i + 1, l.item()))\n",
    "\n",
    "\n",
    "print(conv2d.weight, conv2d.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - 填充与步长"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# 定义一个函数来计算卷积层。它对输入和输出做相应的升维和降维\n",
    "def comp_conv2d(conv2d, X):\n",
    "    # (1, 1)代表批量大小和通道数（“多输入通道和多输出通道”一节将介绍）均为1\n",
    "    X = X.view((1, 1) + X.shape)\n",
    "    Y = conv2d(X)\n",
    "    return Y.view(Y.shape[2:])  # 排除不关心的前两维：批量和通道\n",
    "\n",
    "# 注意这里是两侧分别填充1行或列，所以在两侧一共填充2行或列\n",
    "conv2d = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, padding=1)\n",
    "\n",
    "X = torch.rand(8, 8)\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用高为5、宽为3的卷积核。在高和宽两侧的填充数分别为2和1\n",
    "conv2d = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(5, 3), padding=(2, 1))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1, stride=2)\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(1, 1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - 多输入通道、多输出通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape:  torch.Size([2, 3, 3])\n",
      "K.shape:  torch.Size([2, 2, 2])\n",
      "out.shape:  torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "import d2lzh_pytorch as d2l\n",
    "\n",
    "def corr2d_multi_in(X, K):\n",
    "    # 沿着X和K的第0维（通道维）分别计算再相加\n",
    "    res = d2l.corr2d(X[0, :, :], K[0, :, :])\n",
    "    for i in range(1, X.shape[0]):\n",
    "        res += d2l.corr2d(X[i, :, :], K[i, :, :])\n",
    "    return res\n",
    "\n",
    "\n",
    "X = torch.tensor([[[0, 1, 2], [3, 4, 5], [6, 7, 8]],\n",
    "              [[1, 2, 3], [4, 5, 6], [7, 8, 9]]])\n",
    "K = torch.tensor([[[0, 1], [2, 3]], [[1, 2], [3, 4]]])\n",
    "\n",
    "out = corr2d_multi_in(X, K)\n",
    "\n",
    "## 2通道输入，原始图像为3x3\n",
    "print('X.shape: ', X.size())\n",
    "## 2通道卷积核，尺寸是2x2\n",
    "print('K.shape: ', K.size())\n",
    "## 输出为1通道2x2，因为运算中将不同的输出通道进行了叠加\n",
    "print('out.shape: ', out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 2, 2])\n",
      "torch.Size([3, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "def corr2d_multi_in_out(X, K):\n",
    "    # 对K的第0维遍历，每次同输入X做互相关计算。所有结果使用stack函数合并在一起\n",
    "    return torch.stack([corr2d_multi_in(X, k) for k in K])\n",
    "\n",
    "## conv kernel原为2x2x2的tensor，此处扩展为3x2x2x2的tensor，从而使得\n",
    "## 输出也变为3通道\n",
    "K = torch.stack([K, K + 1, K + 2])\n",
    "print(K.shape) # torch.Size([3, 2, 2, 2])\n",
    "\n",
    "out = corr2d_multi_in_out(X, K)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5403, 0.5927, 0.8335],\n",
      "         [1.0067, 0.1544, 1.0499],\n",
      "         [0.7364, 0.7604, 0.7290]],\n",
      "\n",
      "        [[0.4948, 0.4038, 0.5090],\n",
      "         [0.9144, 0.2914, 1.0752],\n",
      "         [0.9712, 0.4192, 0.7137]]])\n",
      "tensor([[[0.5403, 0.5927, 0.8335],\n",
      "         [1.0067, 0.1544, 1.0499],\n",
      "         [0.7364, 0.7604, 0.7290]],\n",
      "\n",
      "        [[0.4948, 0.4038, 0.5090],\n",
      "         [0.9144, 0.2914, 1.0752],\n",
      "         [0.9712, 0.4192, 0.7137]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def corr2d_multi_in_out_1x1(X, K):\n",
    "    c_i, h, w = X.shape\n",
    "    c_o = K.shape[0]\n",
    "    X = X.view(c_i, h * w)\n",
    "    K = K.view(c_o, c_i)\n",
    "    Y = torch.mm(K, X)  # 全连接层的矩阵乘法\n",
    "    return Y.view(c_o, h, w)\n",
    "\n",
    "X = torch.rand(3, 3, 3)\n",
    "K = torch.rand(2, 3, 1, 1)\n",
    "\n",
    "Y1 = corr2d_multi_in_out_1x1(X, K)\n",
    "Y2 = corr2d_multi_in_out(X, K)\n",
    "\n",
    "print(Y1)\n",
    "print(Y2)\n",
    "\n",
    "(Y1 - Y2).norm().item() < 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - 池化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "tensor([[4., 5.],\n",
      "        [7., 8.]])\n",
      "tensor([[2., 3.],\n",
      "        [5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def pool2d(X, pool_size, mode='max'):\n",
    "    X = X.float()\n",
    "    p_h, p_w = pool_size\n",
    "    Y = torch.zeros(X.shape[0] - p_h + 1, X.shape[1] - p_w + 1)\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == 'max':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].max()\n",
    "            elif mode == 'avg':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()       \n",
    "    return Y\n",
    "\n",
    "X = torch.tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n",
    "print(X)\n",
    "print(pool2d(X, (2, 2)))\n",
    "print(pool2d(X, (2, 2), 'avg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.]],\n",
       "\n",
       "         [[ 1.,  2.,  3.,  4.],\n",
       "          [ 5.,  6.,  7.,  8.],\n",
       "          [ 9., 10., 11., 12.],\n",
       "          [13., 14., 15., 16.]]]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(16, dtype=torch.float).view((1, 1, 4, 4))\n",
    "\n",
    "X = torch.cat((X, X + 1), dim=1)\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]],\n",
       "\n",
       "         [[ 6.,  8.],\n",
       "          [14., 16.]]]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
    "pool2d(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5 - LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LeNet](https://engmrk.com/wp-content/uploads/2018/09/LeNet_Original_Image.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we will use cpu to do training and inference\n",
      "Sequential(\n",
      "  (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (1): Sigmoid()\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (4): Sigmoid()\n",
      "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (6): Flatten()\n",
      "  (7): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (8): Sigmoid()\n",
      "  (9): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (10): Sigmoid()\n",
      "  (11): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "import d2lzh_pytorch as d2l\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('we will use', device, 'to do training and inference')\n",
    "\n",
    "# the tutorial create a new class based on nn.Module, but here to make it simple, we use nn.Sequential\n",
    "LeNet = nn.Sequential(\n",
    "        ##注意，此处输入为1 x 28 x 28的图像（1通道）\n",
    "        nn.Conv2d(1, 6, 5), # in_channels, out_channels, kernel_size\n",
    "        nn.Sigmoid(),\n",
    "        ##conv1输出为6 x 24 x 24\n",
    "        nn.MaxPool2d(2, 2), # kernel_size, stride\n",
    "        ##maxpool1输出为6 x 12 x 12\n",
    "        nn.Conv2d(6, 16, 5),\n",
    "        ##conv2输出为16 x 8 x 8\n",
    "        nn.Sigmoid(),\n",
    "        nn.MaxPool2d(2, 2),\n",
    "        ##maxpool2输出为16 x 4 x 4\n",
    "        #below is fc\n",
    "        nn.Flatten(),\n",
    "        ## 所以下面是16*4*4，如果输入是32x32的图片，那么下面就得变为16*5*5\n",
    "        nn.Linear(16*4*4, 120),\n",
    "        nn.Sigmoid(),\n",
    "        nn.Linear(120, 84),\n",
    "        nn.Sigmoid(),\n",
    "        nn.Linear(84, 10), \n",
    "        )\n",
    "\n",
    "#input: torch.Size([256, 1, 28, 28])\n",
    "#conv1+maxpool1: torch.Size([256, 6, 12, 12])\n",
    "#conv2+maxpool2: torch.Size([256, 16, 4, 4])\n",
    "#flatten: torch.Size([256, 256])\n",
    "#fc1: torch.Size([256, 120])\n",
    "#fc2: torch.Size([256, 84])\n",
    "#fc3: torch.Size([256, 10])\n",
    "\n",
    "   \n",
    "    \n",
    "\n",
    "    \n",
    "### 下面是另一种写法    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        nn.Module.__init__(self)\n",
    "        #卷积层\n",
    "        self.conv1=nn.Conv2d(1,6,5)\n",
    "        self.conv2=nn.Conv2d(6,16,5)\n",
    "        #全连接层\n",
    "        ### \n",
    "        self.fc1 = nn.Linear(16*4*4,120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #conv-relu-pooling\n",
    "        print('input:', x.shape)\n",
    "        x=F.max_pool2d(F.relu(self.conv1(x)),(2,2))\n",
    "        print('conv1+maxpool1:', x.shape)\n",
    "        x=F.max_pool2d(F.relu(self.conv2(x)),2)\n",
    "        print('conv2+maxpool2:', x.shape)\n",
    "        #reshape\n",
    "        x=x.view(x.size()[0],-1)\n",
    "        print('flatten:', x.shape)\n",
    "        x=F.relu(self.fc1(x))\n",
    "        print('fc1:', x.shape)\n",
    "        x=F.relu(self.fc2(x))\n",
    "        print('fc2:', x.shape)\n",
    "        x=self.fc3(x)\n",
    "        print('fc3:', x.shape)\n",
    "        return x\n",
    "\n",
    "net = LeNet\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)\n",
    "\n",
    "# 本函数已保存在d2lzh_pytorch包中方便以后使用。该函数将被逐步改进。\n",
    "def evaluate_accuracy(data_iter, net, device=None):\n",
    "    if device is None and isinstance(net, torch.nn.Module):\n",
    "        # 如果没指定device就使用net的device\n",
    "        device = list(net.parameters())[0].device\n",
    "    acc_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(net, torch.nn.Module):\n",
    "                net.eval() # 评估模式, 这会关闭dropout\n",
    "                acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
    "                net.train() # 改回训练模式\n",
    "            else: # 自定义的模型, 3.13节之后不会用到, 不考虑GPU\n",
    "                if('is_training' in net.__code__.co_varnames): # 如果有is_training这个参数\n",
    "                    # 将is_training设置成False\n",
    "                    acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() \n",
    "                else:\n",
    "                    acc_sum += (net(X).argmax(dim=1) == y).float().sum().item() \n",
    "            n += y.shape[0]\n",
    "    return acc_sum / n\n",
    "\n",
    "# 本函数已保存在d2lzh_pytorch包中方便以后使用\n",
    "def train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs):\n",
    "    net = net.to(device)\n",
    "    print(\"training on \", device)\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, batch_count, start = 0.0, 0.0, 0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            # data to dedicate device, it's important\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_l_sum += l.cpu().item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n",
    "            n += y.shape[0]\n",
    "            batch_count += 1\n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cpu\n",
      "epoch 1, loss 1.0611, train acc 0.591, test acc 0.721, time 10.4 sec\n",
      "epoch 2, loss 0.5409, train acc 0.788, test acc 0.807, time 10.2 sec\n",
      "epoch 3, loss 0.4315, train acc 0.836, test acc 0.843, time 10.2 sec\n",
      "epoch 4, loss 0.3744, train acc 0.860, test acc 0.863, time 10.3 sec\n",
      "epoch 5, loss 0.3381, train acc 0.873, test acc 0.868, time 10.3 sec\n",
      "epoch 6, loss 0.3133, train acc 0.883, test acc 0.868, time 10.2 sec\n",
      "epoch 7, loss 0.3016, train acc 0.887, test acc 0.877, time 10.3 sec\n",
      "epoch 8, loss 0.2817, train acc 0.895, test acc 0.876, time 10.3 sec\n",
      "epoch 9, loss 0.2757, train acc 0.897, test acc 0.870, time 10.3 sec\n",
      "epoch 10, loss 0.2627, train acc 0.901, test acc 0.889, time 10.4 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.01, 10\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6 - AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (4): ReLU()\n",
      "  (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (7): ReLU()\n",
      "  (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (9): ReLU()\n",
      "  (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU()\n",
      "  (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (13): Flatten()\n",
      "  (14): Linear(in_features=6400, out_features=4096, bias=True)\n",
      "  (15): ReLU()\n",
      "  (16): Dropout(p=0.5, inplace=False)\n",
      "  (17): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (18): ReLU()\n",
      "  (19): Dropout(p=0.5, inplace=False)\n",
      "  (20): Linear(in_features=4096, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "import d2lzh_pytorch as d2l\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "'''\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 96, 11, 4), # in_channels, out_channels, kernel_size, stride, padding\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2), # kernel_size, stride\n",
    "            # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数\n",
    "            nn.Conv2d(96, 256, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2),\n",
    "            # 连续3个卷积层，且使用更小的卷积窗口。除了最后的卷积层外，进一步增大了输出通道数。\n",
    "            # 前两个卷积层后不使用池化层来减小输入的高和宽\n",
    "            nn.Conv2d(256, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2)\n",
    "        )\n",
    "         # 这里全连接层的输出个数比LeNet中的大数倍。使用丢弃层来缓解过拟合\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256*5*5, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            # 输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000\n",
    "            nn.Linear(4096, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        feature = self.conv(img)\n",
    "        output = self.fc(feature.view(img.shape[0], -1))\n",
    "        return output\n",
    "'''\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "AlexNet = nn.Sequential(\n",
    "            ### convolution part\n",
    "            nn.Conv2d(1, 96, 11, 4), # in_channels, out_channels, kernel_size, stride, padding\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2), # kernel_size, stride\n",
    "            # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数\n",
    "            nn.Conv2d(96, 256, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2),\n",
    "            # 连续3个卷积层，且使用更小的卷积窗口。除了最后的卷积层外，进一步增大了输出通道数。\n",
    "            # 前两个卷积层后不使用池化层来减小输入的高和宽\n",
    "            nn.Conv2d(256, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2),\n",
    "\n",
    "            ### full connection layers\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256*5*5, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            # 输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000\n",
    "            nn.Linear(4096, 10)\n",
    "            )\n",
    "\n",
    "\n",
    "net = AlexNet\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本函数已保存在d2lzh_pytorch包中方便以后使用\n",
    "def load_data_fashion_mnist(batch_size, resize=None, root='~/Datasets/FashionMNIST'):\n",
    "    \"\"\"Download the fashion mnist dataset and then load into memory.\"\"\"\n",
    "    trans = []\n",
    "    if resize:\n",
    "        trans.append(torchvision.transforms.Resize(size=resize))\n",
    "    trans.append(torchvision.transforms.ToTensor())\n",
    "\n",
    "    transform = torchvision.transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True, download=True, transform=transform)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False, download=True, transform=transform)\n",
    "\n",
    "    train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    return train_iter, test_iter\n",
    "\n",
    "batch_size = 256\n",
    "# 如出现“out of memory”的报错信息，可减小batch_size或resize\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=224)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 0.2136, train acc 0.922, test acc 0.908, time 69.2 sec\n",
      "epoch 2, loss 0.1928, train acc 0.928, test acc 0.917, time 69.1 sec\n",
      "epoch 3, loss 0.1782, train acc 0.933, test acc 0.911, time 69.0 sec\n"
     ]
    }
   ],
   "source": [
    "net = AlexNet\n",
    "#print(net)\n",
    "lr, num_epochs = 0.001, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
